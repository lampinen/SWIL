\documentclass{article}

\usepackage{url}            
\usepackage{booktabs}       
\usepackage{amsfonts}       
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{nicefrac}       
\usepackage{microtype}      
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{natbib}
\usepackage[margin=1in]{geometry}

\newcommand{\R}{\mathbb{R}}

\begin{document}
\section{Theoretical appendix}
\subsection{Preliminaries}
\citet{Saxe2014} provided (in part A of their supplementary material) solutions to learning dynamics in linear networks from arbitrary initial mode strengths, with some assumptions about the initialization and the structure of the data. We note a minor correction to these solutions and build off them here. \par
Consider the input-output correlation matrix $\Sigma_{31} = \sum_{i=1}^P y_ix_i^t$ where $\{(x_1, y_), ..., (x_P, y_P)\}$ are the (input, target) pairs the network is trained on. Saxe and colleagues considered its singular value decomposition:
$$\Sigma_{31} = \sum_{\alpha=1}^{k} u_\alpha s_\alpha v_\alpha^T$$
Saxe and colleagues assumed that the input-input correlation matrix is white ($\Sigma_11 = \sum_{i=1}^P x_i x_i^t = I$), and under the assumption that the network is initialized so that the singular value modes are decoupled, they showed that the modes then remained decoupled and gave exact solutions for the learning of these modes from small initial weights. In the supplementary material, they also expanded this to arbitrary initial weight size (but still assuming decoupled initialization). \par
Specifically, consider singular mode $i$. For ease of explanation, we change the basis of the representational layer of the network so each mode is represented by a single hidden unit -- this is permissable because we assumed the modes were decoupled. We call this the SVD basis. (This is equivalent to the change of variables denoted by bars by Saxe and colleagues.) Let the initial projection of this unit's input weights onto the input mode $v_i$ be $a(0)$, and the initial projection of its output weights onto the output mode $u_i$ be $b(0)$. Saxe and colleagues showed that $(a(t), b(t))$ evolve over time along hyberolas of constant $a^2-b^2$ until they approache $ab = s_i$, i.e. the true strength of that mode in the data. \par
Without loss of generality we assume $a(0) + b(0) > 0$ (the other half-space requires a trivial reparameterization). We can then parameterize this hyperbola by the angle $\theta$ and make the change of variables
$$a = \sqrt{2c_0} \cosh \frac{\theta}{2}, \qquad b = \sqrt{2c_0} \sinh \frac{\theta}{2}$$
Where $c_0 = \frac{1}{2} (a(0)^2-b(0)^2)$ so that
$$ab = c_0 \sinh \theta$$
Following their derivation with this change of variables, we arrive at:
$$\frac{\tau}{2} \frac{d\theta}{dt} = s_i - c_0 \sinh \theta$$
(the factor of two can also be absorbed into the time constant $\tau$, we leave it separate here to avoid changing the definition of $\tau = 1/\lambda$ from the original paper). \par
This differential equation is seperable, and so we can solve for the time needed to traverse along the hyperbola from an initial point $\theta_0$ to a final point $\theta_f$:
$$t = \frac{\tau}{2\sqrt{c_0^2 + s_i^2}} \left[\ln \frac{\sqrt{c_0^2 + s_i^2} + c_0 + s_i \tanh \frac{\theta}{2}}{\sqrt{c_0^2 + s_i^2} - c_0 - s_i \tanh \frac{\theta}{2}}\right]_{\theta_0}^{\theta_f}$$
This provides an exact analytic solution for the time a given degree of learning requires. Although this equation cannot be analytically inverted to find $\theta(t)$ (and thereby $a(t)$ and $b(t)$), we can parametrically sweep through the interval $(\theta_0, \theta_f)$ to plot the theoretical learning curve. \par
%%To aid interpretation, we reverse the substitution:
%%$$t = \frac{\tau}{2\sqrt{c_0^2 + s_i^2}} \left[\ln \frac{\sqrt{c_0^2 + s_i^2} + c_0 + s_i \frac{b}{a}}{\sqrt{c_0^2 + s_i^2} - c_0 - s_i \frac{b}{a}}\right]_{(a(0), b(0))}^{(a(t_f), b(t_f))}$$
We note that 
$$\frac{d(ab)}{dt} = a \frac{db}{dt} + b \frac{da}{dt} = 2 c_0 (s_i - c_0 \sinh \theta) \left( \cosh^2 \frac{\theta}{2} + \sinh^2 \frac{\theta}{2} \right) = 2 c_0 \left(s_i - ab\right) \left(a^2 + b^2 \right)$$
That is, the change in the network's representation of a mode is proportional both to how far the projections are from the correct value (i.e. the error) and to how (absolutely) large the alignments of the input and output modes to the true mode are. The sigmoidal trajectory of mode learning noted by Saxe and colleagues can easily be interpreted from this equation -- with a small weight initialization, the second term is small, and so the change in the strength of the mode is small. As $a$ and $b$ increase, the rate of change increases, until $ab$ approaches its asymptotic value of $s_i$, at which point learning slows down as the error term shrinks. \par
\subsection{Learning from different starting points}
We are now in a position to examine the question of how new knowledge gets integrated into linear networks that have already learned something. Given the above, this reduces to the question of how this new knowledge projects onto the knowledge that is already stored in the network. Qualitatively, new knowledge which provides a minor adjustment of existing knowledge will be rapidly integrated, since the projections of the new singular dimensions onto the old singular dimesnions will be strong (i.e. the second term of $d(ab)/dt$ will be large), and the first term will be proportional to the amount of adaption needed. By contrast, entirely new knowledge (i.e. modes that are orthogonal to all previously learned modes) will be integrated quite slowly. In fact, it will be learned \textbf{over the same period of time as it would have taken to learn this mode in a randomly initialized network}, assuming the modes are decoupled. {\color{red}[simulations here]} \par
Note that it suffices for only the input weights or the output weights but not both to have a strong projection onto the new mode for the adjustment to be rapid -- slow initial learning only occurs when both projections are small, as in the case of small random initializations. \par
\subsection{Learning multiple non-orthogonal new modes}
Unfortunately, this theory only applies exactly when each mode is being adjusted (or learned from scratch) in a way that is orthogonal to all prior modes. However, we have some qualitative understanding of what happens in more complicated situations. When an adjusted mode has some projection onto two previous modes, the corresponding representational modes will \emph{compete} over the new mode. The one with the strongest projection onto it will win out, all else being equal. However, this competition delays the incorporation of the new information. It is difficult to obtain exact analyses of learning in this situation, as the modes are no longer decoupled and their evolution can be quite complex. The overall pattern, however, is that \textbf{competition between two old modes which are both partially aligned with a new mode will delay the learning of the new mode}, and this delay will be worse the more similar the strengths of the projections of the old modes onto the new mode are.\par
Often a new mode has projections onto an old mode (in fact this is generally what the adjustment made to the old mode is fixing when a new mode is incorporated). In this case, the learning of the new mode will be slowed down by the competitive process noted above. Specifically, the new mode will initially try to align with the representation for the old mode, and it is only once the old mode has been adjusted to be orthogonal to the new mode that the new mode can be learned. From the point that the old mode is adjusted, the assumptions of the theory again hold and the learning of the new mode is well described by the theory. In other words, the main effect of some projection of a new mode onto an old mode is a \textbf{delay in the learning of the new mode while the old mode is adjusted}. {\color{red}[simulations here]}




\end{document}
